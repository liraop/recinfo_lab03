{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "data_url=\"https://raw.githubusercontent.com/liraop/recinfo_lab2/master/data/results.csv\"\n",
    "dados = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "documents = dados.text.count()\n",
    "itens = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Escolha uma estratégia de tokenização para a coleção que você está usando e justifique sua estratégia. É importante que você inclua decisões adicionais em relação ao que foi feito no Laboratório anterior (por exemplo, tratamento de maiúsculas/minúsculas e strings numéricas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No lab anterior foi escolhida uma estratégia simples. Foram separadas as palavras consideradas úteis com uso da expressão regular `\\w+`, colocando as palavras todas em caixa-baixa, sendo filtradas pelas condições de não serem *stopwords*, nem conunto de digitos numéricos, além de bigramas. Desta forma se anula boa parte do erro gerado por palavras não adequadas para análise. Contudo, ainda assim há perda de dados que seriam úteis para a análise.\n",
    "\n",
    "#### Neste lab, será utilizado o módulo de *stemming* para português incluída na biblioteca NLTK, bem como os módulos de *stopwords* e *tokenizer*. Na tokenização desta vez consideraremos datas no formato `aaaa` e também entre maiúsculas e minúsculas, adicionando mais complexidade na análise. Primeiro faremos a tokenização mais geral, separando as palavras, depois será feita a tokenização das datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token = rpt(r'\\w+')\n",
    "year_token = rpt(r'\\d{4}')\n",
    "\n",
    "def tokenize_it(dataset, pattern, words):\n",
    "\n",
    "    for artigo in dataset.text:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(artigo):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O método `tokenize_it` faz a aplicação dos *patterns* definidos, de modo que nosso conjunto de palavras seja incrementado de acordo com o processo de tokenização. \n",
    "\n",
    "#### A variável `word_token` utiliza a mesma regex do outro lab. Contudo, dentro do método, não é feita nenhuma modificação no texto analizado. Desta forma, tanto palavras com maiúsculas e minúsculas são adicionadas ao vocábulo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Refaça a questão 2 do Laboratório anterior usando os tokens produzidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>frequencia</th>\n",
       "      <th>r</th>\n",
       "      <th>PR</th>\n",
       "      <th>r.PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anos</td>\n",
       "      <td>1166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sobre</td>\n",
       "      <td>832</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>presidente</td>\n",
       "      <td>824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>752</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>666</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>país</td>\n",
       "      <td>578</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ainda</td>\n",
       "      <td>578</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Governo</td>\n",
       "      <td>560</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contra</td>\n",
       "      <td>476</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pessoas</td>\n",
       "      <td>470</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>porque</td>\n",
       "      <td>446</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dois</td>\n",
       "      <td>442</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>432</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>onde</td>\n",
       "      <td>416</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pode</td>\n",
       "      <td>404</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feira</td>\n",
       "      <td>400</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>todos</td>\n",
       "      <td>398</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>parte</td>\n",
       "      <td>384</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tempo</td>\n",
       "      <td>382</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reais</td>\n",
       "      <td>380</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fazer</td>\n",
       "      <td>378</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mundo</td>\n",
       "      <td>376</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>374</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>menos</td>\n",
       "      <td>364</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>segundo</td>\n",
       "      <td>358</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>disse</td>\n",
       "      <td>354</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vida</td>\n",
       "      <td>348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>política</td>\n",
       "      <td>342</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>outros</td>\n",
       "      <td>338</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>primeiro</td>\n",
       "      <td>336</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>três</td>\n",
       "      <td>330</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ministro</td>\n",
       "      <td>328</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>maior</td>\n",
       "      <td>326</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>milhões</td>\n",
       "      <td>326</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>antes</td>\n",
       "      <td>322</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>primeira</td>\n",
       "      <td>316</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>caso</td>\n",
       "      <td>316</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>apenas</td>\n",
       "      <td>312</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>durante</td>\n",
       "      <td>310</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>desde</td>\n",
       "      <td>306</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016</td>\n",
       "      <td>304</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>havia</td>\n",
       "      <td>298</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>outro</td>\n",
       "      <td>296</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2017</td>\n",
       "      <td>296</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>trabalho</td>\n",
       "      <td>294</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ditadura</td>\n",
       "      <td>294</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>história</td>\n",
       "      <td>280</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>dias</td>\n",
       "      <td>276</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>agora</td>\n",
       "      <td>270</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cada</td>\n",
       "      <td>270</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       palavra  frequencia     r    PR   r.PR\n",
       "0         anos        1166   1.0  0.51  0.005\n",
       "1        sobre         832   2.0  0.36  0.007\n",
       "2   presidente         824   3.0  0.36  0.011\n",
       "3    Bolsonaro         752   4.0  0.33  0.013\n",
       "4       Brasil         666   5.0  0.29  0.014\n",
       "5         país         578   6.0  0.25  0.015\n",
       "6        ainda         578   7.0  0.25  0.018\n",
       "7      Governo         560   8.0  0.24  0.019\n",
       "8       contra         476   9.0  0.21  0.019\n",
       "9      pessoas         470  10.0  0.21  0.021\n",
       "10      porque         446  11.0  0.19  0.021\n",
       "11        dois         442  12.0  0.19  0.023\n",
       "12        2018         432  13.0  0.19  0.025\n",
       "13        onde         416  14.0  0.18  0.025\n",
       "14        pode         404  15.0  0.18  0.027\n",
       "15       feira         400  16.0  0.17  0.027\n",
       "16       todos         398  17.0  0.17  0.029\n",
       "17       parte         384  18.0  0.17  0.031\n",
       "18       tempo         382  19.0  0.17  0.032\n",
       "19       reais         380  20.0  0.17  0.034\n",
       "20       fazer         378  21.0  0.16  0.034\n",
       "21       mundo         376  22.0  0.16  0.035\n",
       "22    mulheres         374  23.0  0.16  0.037\n",
       "23       menos         364  24.0  0.16  0.038\n",
       "24     segundo         358  25.0  0.16  0.040\n",
       "25       disse         354  26.0  0.15  0.039\n",
       "26        vida         348  27.0  0.15  0.040\n",
       "27    política         342  28.0  0.15  0.042\n",
       "28      outros         338  29.0  0.15  0.044\n",
       "29    primeiro         336  30.0  0.15  0.045\n",
       "30        três         330  31.0  0.14  0.043\n",
       "31    ministro         328  32.0  0.14  0.045\n",
       "32       maior         326  33.0  0.14  0.046\n",
       "33     milhões         326  34.0  0.14  0.048\n",
       "34       antes         322  35.0  0.14  0.049\n",
       "35    primeira         316  36.0  0.14  0.050\n",
       "36        caso         316  37.0  0.14  0.052\n",
       "37      apenas         312  38.0  0.14  0.053\n",
       "38     durante         310  39.0  0.14  0.055\n",
       "39       desde         306  40.0  0.13  0.052\n",
       "40        2016         304  41.0  0.13  0.053\n",
       "41       havia         298  42.0  0.13  0.055\n",
       "42       outro         296  43.0  0.13  0.056\n",
       "43        2017         296  44.0  0.13  0.057\n",
       "44    trabalho         294  45.0  0.13  0.058\n",
       "45    ditadura         294  46.0  0.13  0.060\n",
       "46    história         280  47.0  0.12  0.056\n",
       "47        dias         276  48.0  0.12  0.058\n",
       "48       agora         270  49.0  0.12  0.059\n",
       "49        cada         270  50.0  0.12  0.060"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_it(dados, word_token, itens)\n",
    "tokenize_it(dados, year_token, itens)\n",
    "\n",
    "df = pd.DataFrame(itens, columns=['palavra'])\n",
    "itens_df = df.palavra.value_counts().reset_index()\n",
    "itens_df.columns = ['palavra', 'frequencia']\n",
    "itens_df['r'] = itens_df.frequencia.rank(ascending=False, method='first')\n",
    "\n",
    "over_1000 = len(itens_df[itens_df.frequencia > 1000])\n",
    "singletons = len(itens_df[itens_df.frequencia == 1])\n",
    "total_itens = len(itens)\n",
    "vocab = len(set(itens))\n",
    "\n",
    "itens_df[\"PR\"] = round((itens_df.frequencia / total_itens) * 100, 2)\n",
    "itens_df[\"r.PR\"] = round(itens_df.r * itens_df[\"PR\"] / 100, 3)\n",
    "itens_df[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aplique Stemming nos tokens produzidos e encontre 10 exemplos de falsos positivos e 10 exemplos de falsos negativos. Que impacto você acha que falsos positivos e negativos, como esses, teriam no processamento de consultas? Dê exemplos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Refaça a questão 3 do Laboratório anterior usando os tokens stemizados. Você percebeu alguma diferença em relação aos tokens sem stemming? Se sim, quais?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
