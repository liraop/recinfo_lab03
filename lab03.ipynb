{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Escolha uma estratégia de tokenização para a coleção que você está usando e justifique sua estratégia. É importante que você inclua decisões adicionais em relação ao que foi feito no Laboratório anterior (por exemplo, tratamento de maiúsculas/minúsculas e strings numéricas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No lab anterior foi escolhida uma estratégia simples. Foram separadas as palavras consideradas úteis com uso da expressão regular `\\w+`, colocando as palavras todas em caixa-baixa, sendo filtradas pelas condições de não serem *stopwords*, nem conunto de digitos numéricos, além de bigramas. Desta forma se anula boa parte do erro gerado por palavras não adequadas para análise. Contudo, ainda assim há perda de dados que seriam úteis para a análise.\n",
    "\n",
    "#### Neste lab, será utilizado o módulo de *stemming* para português incluída na biblioteca NLTK, bem como os módulos de *stopwrods* e *tokenizer*. Na tokenização desta vez consideraremos datas no formato `aaaa` e também entre maiúsculas e minúsculas, adicionando mais complexidade na análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Refaça a questão 2 do Laboratório anterior usando os tokens produzidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/liraop/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/liraop/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "#regex para pegar apenas palavras não pontuadas\n",
    "word_token = rpt(r'\\w+')\n",
    "\n",
    "def tokenize_it(dataset, pattern, words):\n",
    "\n",
    "    for artigo in dataset.text:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(artigo.lower()):\n",
    "        #se não é stopword e não é bigrama...\n",
    "            if token not in stopwords and len(token) > 3 and not bool(re.search(r'\\d', token)):\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "\n",
    "\n",
    "data_url=\"https://raw.githubusercontent.com/liraop/recinfo_lab2/master/data/results.csv\"\n",
    "dados = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "n_documentos = dados.text.count()\n",
    "palavras = []\n",
    "tokenize_it(dados, word_token, palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aplique Stemming nos tokens produzidos e encontre 10 exemplos de falsos positivos e 10 exemplos de falsos negativos. Que impacto você acha que falsos positivos e negativos, como esses, teriam no processamento de consultas? Dê exemplos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Refaça a questão 3 do Laboratório anterior usando os tokens stemizados. Você percebeu alguma diferença em relação aos tokens sem stemming? Se sim, quais?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
